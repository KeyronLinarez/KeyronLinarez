[
  {
    "objectID": "project3.html",
    "href": "project3.html",
    "title": "Project 3",
    "section": "",
    "text": "Using the “College tuition, diversity, and pay” data set, I will be analyzing the differences in cost/tuition between public and private schools. I will filter out the data in order to make a fair comparison between the two categories (e.g. schools in the same region), then compare the difference between their costs. Here is a link to my data set: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-03-10/readme.md\nMy research questions: Alternative claim: Tuition rates are higher for private universities than for public universities Null claim: Tuition rates do not differ between public and private universities.\nI am only interested in the total cost for students attending schools in-state, in California. This way, the cost-of-living is fairly looked at (since comparing Californiaa schools with Maine schools, for example, would not be fair).\n\nlibrary(dplyr)\n\n# Sorting my data:\nCA_schools &lt;- tuition_cost |&gt;\n  select(name, state_code, type, in_state_tuition) |&gt;\n  filter(state_code == \"CA\")\n\n\n# public schools\npublic_schools &lt;- tuition_cost |&gt;\n  select(name, state_code, type, in_state_tuition) |&gt;\n  filter(type == \"Public\") |&gt;\n  filter(state_code == \"CA\")\n\npublic_mean &lt;- public_schools |&gt;\n  summarize(mean_cost = mean(in_state_tuition, na.rm = TRUE))\n\n#145 total public schools\npublic_schools\n\n# A tibble: 145 × 4\n   name                                        state_code type  in_state_tuition\n   &lt;chr&gt;                                       &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;\n 1 Allan Hancock College                       CA         Publ…             1418\n 2 American River College                      CA         Publ…             1416\n 3 Antelope Valley College                     CA         Publ…             1420\n 4 Bakersfield College                         CA         Publ…             1418\n 5 Barstow Community College                   CA         Publ…             1391\n 6 Berkeley City College                       CA         Publ…             1432\n 7 Butte College                               CA         Publ…             1498\n 8 Cabrillo College                            CA         Publ…             1500\n 9 California Maritime Academy                 CA         Publ…             7135\n10 California Polytechnic State University: S… CA         Publ…             9816\n# ℹ 135 more rows\n\nround(public_mean)\n\n# A tibble: 1 × 1\n  mean_cost\n      &lt;dbl&gt;\n1      3180\n\n# private schools\nprivate_schools &lt;- tuition_cost |&gt;\n  select(name, state_code, type, in_state_tuition) |&gt;\n  filter(type == \"Private\") |&gt;\n  filter(state_code == \"CA\") \n\nprivate_mean &lt;- private_schools |&gt;\n  summarize(mean_cost = mean(in_state_tuition, na.rm = TRUE))\n\n# 94 total private schools\nprivate_schools\n\n# A tibble: 94 × 4\n   name                                    state_code type    in_state_tuition\n   &lt;chr&gt;                                   &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt;\n 1 Alliant International University        CA         Private            18000\n 2 American Academy of Dramatic Arts: West CA         Private            35160\n 3 American Jewish University              CA         Private            31826\n 4 Antioch University Los Angeles          CA         Private            20670\n 5 Antioch University Santa Barbara        CA         Private            22575\n 6 Art Center College of Design            CA         Private            43416\n 7 Azusa Pacific University                CA         Private            38880\n 8 Bergin University of Canine Studies     CA         Private             9450\n 9 Bethesda University of California       CA         Private             8350\n10 Beverly Hills Design Institute          CA         Private            31060\n# ℹ 84 more rows\n\nround(private_mean)\n\n# A tibble: 1 × 1\n  mean_cost\n      &lt;dbl&gt;\n1     32426\n\n\n\n# My function to simulate a random sampling of school's in-state tuition\n\nset.seed(1993)\n\nrandom_sample &lt;- function(rep, sample_size) {\n  # grabs a slice of schools at \n  sampled_schools &lt;- CA_schools |&gt;\n    sample_n(size = sample_size, replace = FALSE)\n  \n  # mean for public schools\n  mean_public_tuition &lt;- sampled_schools |&gt;\n    filter(type == \"Public\") |&gt;\n    summarize(mean_tuition = mean(in_state_tuition, na.rm = TRUE)) |&gt;\n    pull(mean_tuition)\n  \n  # mean for private schools\n  mean_private_tuition &lt;- sampled_schools |&gt;\n    filter(type == \"Private\") |&gt;\n    summarize(mean_tuition = mean(in_state_tuition, na.rm = TRUE)) |&gt;\n    pull(mean_tuition)\n  \n  difference &lt;- mean_private_tuition - mean_public_tuition\n  return(difference)\n}\n\n# Calculate the difference in the previous observed means\nobserved_diff &lt;- as.integer(private_mean - public_mean) \n\n# 1000 iterations\nnum_exper &lt;- 2000\nsimulated_differences &lt;- map_dbl(1:num_exper, random_sample, sample_size = 100)\n\nsimulated_differences |&gt; \n  data.frame() |&gt; \n  ggplot(aes(x = simulated_differences)) + \n  geom_histogram(binwidth = 500, fill = \"pink\", color = \"white\") + \n  geom_vline(aes(xintercept = observed_diff), color = \"red\") +\n  labs(x = \"The difference of mean cost of attendance betwen Public and Private Universities\",\n       title = \"Sampling distribution when null hypothesis is true\")\n\n\n\n\n\n\n\np_value &lt;- mean(abs(simulated_differences) &gt;= abs(observed_diff))\np_value\n\n[1] 0.5115\n\n\nThis plot shows us the results from randomly shuffling all of the tuition costs between public and private universities, and then measuring their mean difference.\nFrom these data, the observed differences seem to be consistent with the distribution of differences in the null sampling distribution.\nThere is no strong evidence to reject the null hypothesis.\nWe can claim that the tuition rates are not higher for private universities than for public universities (p-value = .502).\nWe achieved this result by filtering for California schools, and then calculating the average mean between private and public schools in California. We then created a random sampling by cutting a slice of elements from the data set of all Californian schools, and randomly shuffling their tuition values. We ran this over 2000 iterations, and found that there is strong evidence for the null hypothesis in this case."
  },
  {
    "objectID": "mario_kart.html",
    "href": "mario_kart.html",
    "title": "Campus Pride Index Analysis",
    "section": "",
    "text": "Below, you will find a box plot highlighting the Campus Pride Index’s scores varying across campus community sizes. There is a correlation between community size and ratings, with smaller communities generally scoring lower among queer students (with a few notable exceptions).\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(httr2)\n\ntuesdata &lt;- tidytuesdayR::tt_load(2024, week = 24)\n\npride_index &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-06-11/pride_index.csv')\npride_index_tags &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-06-11/pride_index_tags.csv')\n\ncolnames(pride_index)\n\ncommunity_type &lt;- pride_index$community_type\nrating &lt;- pride_index$rating\n\nggplot(data = pride_index, aes(x = community_type, y = rating)) +\n  geom_boxplot() +   \n  labs(\n    x = \"Community Type\",\n    y = \"Rating\",\n    title = \"Campus Pride Index, Sorted by Community Size\"\n  ) + theme_minimal()"
  },
  {
    "objectID": "curly_hair.html",
    "href": "curly_hair.html",
    "title": "Diwali Sales Data",
    "section": "",
    "text": "Below, you will find a plot showcasing the number of purchases for different age groups during Diwali, the festival of lights. The color gradient shows the amount in Indian rupees spent by each customer, revealing how age group impacts total rupees spent with respect to total orders made.\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(httr2)\n\nhouse &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-11-14/diwali_sales_data.csv')\n\ncolnames(house)\nage_group &lt;- house$`Age Group`\nOrders &lt;- house$Orders\nAmount &lt;- house$Amount\n\n\nggplot(data = house, aes(x = `Age Group`, y = Orders, color = Amount)) +\n  geom_col() +   \n  labs(\n    x = \"Age Group\",\n    y = \"Number of Orders\",\n    title = \"Diwali Orders Made by Age\"\n  ) + theme_minimal()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I will be uploading some projects (personal and/or academic) to the following pages. As an experiment in R, I will add two graphs analyzing some data sets.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Keyron Linarez",
    "section": "",
    "text": "Hello! I am Keyron Linarez, a Computer Science and Math student attending Pomona College. I have a deep love for history, social justice movements, and music (especially disruptive music that embodies all three). To learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "project2.html",
    "href": "project2.html",
    "title": "Project 2",
    "section": "",
    "text": "I am practicing my data science and regular expression skills by working with a big data set!\nI will be analyzing the Dear Abby data set. I found this data set very interesting due to its annonymous nature, especially since it has existed long before internet threads were commonplace. I performed two analyses - one on the titles, and another on the questions themseles.\nHere is where I retrieved my data: https://github.com/the-pudding/data/blob/master/dearabby/raw_da_qs.csv\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(tidytext)\nlibrary(dplyr)\nlibrary(tm)\nabby &lt;- read_csv(\"https://raw.githubusercontent.com/the-pudding/data/master/dearabby/raw_da_qs.csv\")\n\n# tokenize dear abby dataset - tidytext!\ntidyabby &lt;- abby |&gt;\n  unnest_tokens(word, title)\n\n# create frequency dataframe\ncount &lt;- tidyabby|&gt;\n  count(word, sort = TRUE)\n\n# REGEX - remove all 3 letter words\ncount &lt;- count |&gt;\n  mutate(word = case_when(\n    str_detect(word, \"\\\\b\\\\w{1,4}\\\\b\") ~ str_remove_all(word, \"\\\\b\\\\w{1,4}\\\\b\"),\n    TRUE ~ word\n  ))\n\n# REGEX - remove all punctuation\ncount &lt;- count |&gt;\n  mutate(word = str_remove_all(word, \"\\\\p{P}\")) |&gt;\n  filter(word != \"\")\n\n#view(count)\n\n# create ggplot\ncount |&gt;\n  filter(n &gt; 540) |&gt;\n  ggplot() +\n    geom_col(aes(x = word, y = n)) +   \n    labs(\n      x = \"Words From Titles\",\n      y = \"Frequency Count\",\n      title = \"Most Commonly Used Words in Dear Abby Titles\"\n    ) + theme_minimal()\n\n\n\n\n\n\n\n\nFor my first plot, I first created a frequency list across the entire title data set. Using the most frequent words, I then filtered by the top 10 (I performed several regex operations to get rid of common English filler words). From the graph, you can see the common theme of family, marriage, and children as very prominent sources of anxiety features in Dear Abby. I also believe “should” is a very essential word, as it highlights the important question of not knowing what to do - i.e. the reader’s relationship coming to Abby for advice. In the data set’s documentation, they mention that about 70% of Dear Abby readers are women, which I think might explain the high frequency in the word ‘Woman’, though this is just my best guess.\nFor my next plot, I wanted to take the year value into account to try and note a change over time within Dear Abby questions. I performed less string processing and simply captured the initial parts of the questions themselves, and then created a frequency list from that data.\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(tidytext)\nlibrary(dplyr)\nlibrary(tm)\n\n# downloading the dataset\nabby &lt;- read_csv(\"https://raw.githubusercontent.com/the-pudding/data/master/dearabby/raw_da_qs.csv\")\n\n# REGEX - Filter out questions to include just the first 4 words\nabby &lt;- abby |&gt;\n  mutate(question_only = str_extract(question_only, \"^(?:\\\\S+\\\\s+){0,3}\\\\S+\"))\n\n#head(abby$question_only)\n\n# Count the most used questions by year\nword_count_by_year &lt;- abby |&gt;\n  group_by(year, question_only) |&gt;  # Group by year and question_only\n  summarise(count = n(), .groups = \"drop\") |&gt; # Count occurrences\n  arrange(year, desc(count))  # Arrange by year and count\n\n# Get the most common phrase for each year\nword_count_by_year &lt;- word_count_by_year %&gt;%\n  group_by(year) %&gt;%\n  slice_max(order_by = count, n = 1, with_ties = TRUE)  # Get the top phrase\n\n# gg plot, with specefic label alteration (the year labels were harder to see!!\nword_count_by_year |&gt;\n  ggplot(aes(x = factor(year), y = count, fill = question_only)) +\n    geom_col() +   \n    labs(\n      x = \"Year\",\n      y = \"Frequency\",\n      title = \"Most Common Starting Phrases in Dear Abby Questions\"\n    ) + \n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7),  # Smaller x-axis labels\n          legend.text = element_text(size = 8)) +  # Optional: smaller legend text\n    scale_fill_discrete(name = \"Phrase\") \n\n\n\n\n\n\n\n\nThis plot is dominated by “my husband and i” across most of Dear Abby’s history. While the topics and questions across the decades most definitely change, I think this plot highlights that the core of reader’s anxieties always involve marriage. Interestingly, 1991 was impacted by a specific phrase attached to many questions, which I believe could have been solved with stronger regex filtering. 2015 also showed a tie between two phrases, both of which still circle marriage. Before starting this project, I wanted to gain insight into US culture. I honestly had no idea how important marriage was to the US, and I think I have a better idea of how love continues to circulate in people’s lives as they get older (and how much advice people need to make it run smooth!)."
  }
]