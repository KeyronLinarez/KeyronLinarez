[
  {
    "objectID": "wai.html",
    "href": "wai.html",
    "title": "SQL Practice with WAI Database",
    "section": "",
    "text": "For this project, I will be manipulating the Wideband acoustic immittance SQL data base to make some observations on their results. I will practice by re-creating the graph displayed on their website, which 12 of their data sets graphed according to frequency. I will then pick a data set and compare the results between sex. Here is their official website/citation: doi.org/10.35482/egr.001.2022\n\nlibrary(tidyverse)\nlibrary(RMariaDB)\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n\nSELECT Identifier, Frequency, LOG10(Frequency) AS logFreq, AVG(Absorbance) AS avgAbsorb\nFROM Measurements\nWHERE Identifier IN (\"Abur_2014\", \"Feeney_2017\", \"Groon_2015\", \"Lewis_2015\", \"Liu_2008\", \"Rosowski_2012\", \"Shahnaz_2006\", \"Shaver_2013\", \"Sun_2016\", \"Voss_1994\", \"Voss_2010\", \"Werner_2010\") AND Frequency &lt; 8000 AND Frequency &gt; 200\nGROUP BY Frequency, Identifier\n\n\n# combining two different data sets\nSELECT p.Identifier, p.AuthorsShortList, p.Year, COUNT(DISTINCT SubjectNumber, Ear) as N_ears, AVG(Absorbance) AS avgAbsorb, Frequency, \n CONCAT(p.AuthorsShortList, \" (\", p.Year, \") N=\", COUNT(DISTINCT SubjectNumber, Ear), \"; \") AS label\n  FROM PI_Info as p\nLEFT JOIN Measurements as m ON m.Identifier = p.Identifier\nWHERE m.Identifier IN (\"Abur_2014\", \"Feeney_2017\", \"Groon_2015\", \"Lewis_2015\", \"Liu_2008\", \"Rosowski_2012\", \"Shahnaz_2006\", \"Shaver_2013\", \"Sun_2016\", \"Voss_1994\", \"Voss_2010\", \"Werner_2010\") AND Frequency &lt; 8000 AND Frequency &gt; 200\nGROUP BY Frequency, Identifier\n\n\nggplot(final_table, aes(x = Frequency, y = avgAbsorb, color = label)) +\n  geom_line(size = 1) +  # Use geom_line for lines\n  labs(\n    title = \"Mean Absorbance from each publication in WAI database\",\n    x = \"Frequency (Hz)\",\n    y = \"Mean Absorbance\",\n    color = \"\"\n  ) +\nscale_x_log10(breaks = c(200, 400, 600, 800, 1000, 2000, 4000, 6000, 8000))+ \nscale_y_continuous(breaks = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1)) +\n  theme(\n    axis.text.x = element_text(size = 8),  \n    axis.text.y = element_text(size = 8) \n  )\n\n\n\n\n\n\n\n\nThis graph is a re-creation of the author’s frequency graph, which has 12 specefic papers results mapped out on a log scale.\n\n# if weird data -&gt; facet_wrap(~sex/race/etc)\nSELECT Identifier, Frequency, LOG10(Frequency) AS logFreq, AVG(Absorbance) AS avgAbsorb\nFROM Measurements\nWHERE Identifier IN (\"Shaver_2013\")\nGROUP BY Frequency, Identifier\n\n\n\nSELECT s.SubjectNumber, s.Sex as sex, AVG(Absorbance) AS avgAbsorb, m.Frequency\nFROM Subjects as s\nLEFT JOIN Measurements as m ON m.Identifier = s.Identifier\nWHERE m.Identifier IN (\"Shaver_2013\")\nGROUP BY s.SubjectNumber, s.Sex, m.Frequency;\n\n\nggplot(final_subjects, aes(x = Frequency, y = avgAbsorb, color = sex)) +\n  geom_line(size = 1) +  # Use geom_line for lines\n  labs(\n    title = \"Mean Absorbance from Shaver 2013\",\n    x = \"Frequency (Hz)\",\n    y = \"Mean Absorbance\",\n  ) +\nscale_x_log10(breaks = c(200, 400, 600, 800, 1000, 2000, 4000, 6000, 8000))+ \nscale_y_continuous(breaks = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1)) +\n  theme(\n    axis.text.x = element_text(size = 6),  \n    axis.text.y = element_text(size = 8) \n  ) + facet_wrap(~ sex)\n\n\n\n\n\n\n\n# terminate our sql connection!\nDBI::dbDisconnect(con_wai, shutdown = TRUE)\n\nThese two graphs show the differences betwen mean absorption between males and females measured from the Shaver 2013 study. As you can see, not much difference was recorded.\nThank you!"
  },
  {
    "objectID": "project2.html",
    "href": "project2.html",
    "title": "Regular Expressions with Dear Abby",
    "section": "",
    "text": "I am practicing my data science and regular expression skills by working with a big data set!\nI will be analyzing the Dear Abby data set. I found this data set very interesting due to its annonymous nature, especially since it has existed long before internet threads were commonplace. I performed two analyses - one on the titles, and another on the questions themseles.\nHere is where I retrieved my data: https://github.com/the-pudding/data/blob/master/dearabby/raw_da_qs.csv\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(tidytext)\nlibrary(dplyr)\nlibrary(tm)\nabby &lt;- read_csv(\"https://raw.githubusercontent.com/the-pudding/data/master/dearabby/raw_da_qs.csv\")\n\n# tokenize dear abby dataset - tidytext!\ntidyabby &lt;- abby |&gt;\n  unnest_tokens(word, title)\n\n# create frequency dataframe\ncount &lt;- tidyabby|&gt;\n  count(word, sort = TRUE)\n\n# REGEX - remove all 3 letter words\ncount &lt;- count |&gt;\n  mutate(word = case_when(\n    str_detect(word, \"\\\\b\\\\w{1,4}\\\\b\") ~ str_remove_all(word, \"\\\\b\\\\w{1,4}\\\\b\"),\n    TRUE ~ word\n  ))\n\n# REGEX - remove all punctuation\ncount &lt;- count |&gt;\n  mutate(word = str_remove_all(word, \"\\\\p{P}\")) |&gt;\n  filter(word != \"\")\n\n#view(count)\n\n# create ggplot\ncount |&gt;\n  filter(n &gt; 540) |&gt;\n  ggplot() +\n    geom_col(aes(x = word, y = n)) +   \n    labs(\n      x = \"Words From Titles\",\n      y = \"Frequency Count\",\n      title = \"Most Commonly Used Words in Dear Abby Titles\"\n    ) + theme_minimal()\n\n\n\n\n\n\n\n\nFor my first plot, I first created a frequency list across the entire title data set. Using the most frequent words, I then filtered by the top 10 (I performed several regex operations to get rid of common English filler words). From the graph, you can see the common theme of family, marriage, and children as very prominent sources of anxiety features in Dear Abby. I also believe “should” is a very essential word, as it highlights the important question of not knowing what to do - i.e. the reader’s relationship coming to Abby for advice. In the data set’s documentation, they mention that about 70% of Dear Abby readers are women, which I think might explain the high frequency in the word ‘Woman’, though this is just my best guess.\nFor my next plot, I wanted to take the year value into account to try and note a change over time within Dear Abby questions. I performed less string processing and simply captured the initial parts of the questions themselves, and then created a frequency list from that data.\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(tidytext)\nlibrary(dplyr)\nlibrary(tm)\n\n# downloading the dataset\nabby &lt;- read_csv(\"https://raw.githubusercontent.com/the-pudding/data/master/dearabby/raw_da_qs.csv\")\n\n# REGEX - Filter out questions to include just the first 4 words\nabby &lt;- abby |&gt;\n  mutate(question_only = str_extract(question_only, \"^(?:\\\\S+\\\\s+){0,3}\\\\S+\"))\n\n#head(abby$question_only)\n\n# Count the most used questions by year\nword_count_by_year &lt;- abby |&gt;\n  group_by(year, question_only) |&gt;  # Group by year and question_only\n  summarise(count = n(), .groups = \"drop\") |&gt; # Count occurrences\n  arrange(year, desc(count))  # Arrange by year and count\n\n# Get the most common phrase for each year\nword_count_by_year &lt;- word_count_by_year %&gt;%\n  group_by(year) %&gt;%\n  slice_max(order_by = count, n = 1, with_ties = TRUE)  # Get the top phrase\n\n# gg plot, with specefic label alteration (the year labels were harder to see!!\nword_count_by_year |&gt;\n  ggplot(aes(x = factor(year), y = count, fill = question_only)) +\n    geom_col() +   \n    labs(\n      x = \"Year\",\n      y = \"Frequency\",\n      title = \"Most Common Starting Phrases in Dear Abby Questions\"\n    ) + \n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7),  # Smaller x-axis labels\n          legend.text = element_text(size = 8)) +  # Optional: smaller legend text\n    scale_fill_discrete(name = \"Phrase\") \n\n\n\n\n\n\n\n\nThis plot is dominated by “my husband and i” across most of Dear Abby’s history. While the topics and questions across the decades most definitely change, I think this plot highlights that the core of reader’s anxieties always involve marriage. Interestingly, 1991 was impacted by a specific phrase attached to many questions, which I believe could have been solved with stronger regex filtering. 2015 also showed a tie between two phrases, both of which still circle marriage. Before starting this project, I wanted to gain insight into US culture. I honestly had no idea how important marriage was to the US, and I think I have a better idea of how love continues to circulate in people’s lives as they get older (and how much advice people need to make it run smooth!)."
  },
  {
    "objectID": "mario_kart.html",
    "href": "mario_kart.html",
    "title": "Campus Pride Index Analysis",
    "section": "",
    "text": "Below, you will find a box plot highlighting the Campus Pride Index’s scores varying across campus community sizes. There is a correlation between community size and ratings, with smaller communities generally scoring lower among queer students (with a few notable exceptions).\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(httr2)\n\ntuesdata &lt;- tidytuesdayR::tt_load(2024, week = 24)\n\npride_index &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-06-11/pride_index.csv')\npride_index_tags &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-06-11/pride_index_tags.csv')\n\ncolnames(pride_index)\n\ncommunity_type &lt;- pride_index$community_type\nrating &lt;- pride_index$rating\n\nggplot(data = pride_index, aes(x = community_type, y = rating)) +\n  geom_boxplot() +   \n  labs(\n    x = \"Community Type\",\n    y = \"Rating\",\n    title = \"Campus Pride Index, Sorted by Community Size\"\n  ) + theme_minimal()"
  },
  {
    "objectID": "curly_hair.html",
    "href": "curly_hair.html",
    "title": "Diwali Sales Data",
    "section": "",
    "text": "Below, you will find a plot showcasing the number of purchases for different age groups during Diwali, the festival of lights. The color gradient shows the amount in Indian rupees spent by each customer, revealing how age group impacts total rupees spent with respect to total orders made.\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(httr2)\n\nhouse &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-11-14/diwali_sales_data.csv')\n\ncolnames(house)\nage_group &lt;- house$`Age Group`\nOrders &lt;- house$Orders\nAmount &lt;- house$Amount\n\n\nggplot(data = house, aes(x = `Age Group`, y = Orders, color = Amount)) +\n  geom_col() +   \n  labs(\n    x = \"Age Group\",\n    y = \"Number of Orders\",\n    title = \"Diwali Orders Made by Age\"\n  ) + theme_minimal()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hello, my name is Keyron (they/them), I am a current senior studying computer science at Pomona college. I am a first generation student and a Questbridge scholar, and I really like video games :3\nI’ve included some of my projects for you to see on my website: research, data science, and programming projects from the last several years. Thanks for stopping by!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Keyron Linarez",
    "section": "",
    "text": "Hello! I am Keyron Linarez, a Computer Science and Math student attending Pomona College. I have a deep love for programming, social justice movements, and music. Thanks for stopping by!"
  },
  {
    "objectID": "presentation.html#goals",
    "href": "presentation.html#goals",
    "title": "Project 5 - Website Updates",
    "section": "Goals",
    "text": "Goals\n\nFix Project 3 and 4\nTry to get a custom domain name!\nClean up my about me section\nMake everything fit with a dark theme"
  },
  {
    "objectID": "presentation.html#buying-a-domain",
    "href": "presentation.html#buying-a-domain",
    "title": "Project 5 - Website Updates",
    "section": "Buying a Domain",
    "text": "Buying a Domain\n\nGithub pages allows us to use custom domain names!\nThis requires us to purchase a custom domain, and to verify it through github\nI’ve begun the process of buying a domain, and spent some time researching how to verify it. However, as you can see, It hasn’t happened yet (more time and money needed)"
  },
  {
    "objectID": "presentation.html#fixing-project-3",
    "href": "presentation.html#fixing-project-3",
    "title": "Project 5 - Website Updates",
    "section": "Fixing Project 3",
    "text": "Fixing Project 3\nFor my original attempt at creating a null sampling distribution, I incorrectly shuffled the income between all public and private schools, instead of switching the public/private labels.\n\nI fixed this!\nNow it’s very obvious that the null hypothesis is FALSE\nUpdated colors and added descriptive text to fit with dark theme"
  },
  {
    "objectID": "presentation.html#updating-project-4",
    "href": "presentation.html#updating-project-4",
    "title": "Project 5 - Website Updates",
    "section": "Updating Project 4",
    "text": "Updating Project 4\n\nAdded proper citations + added more descriptive comments\nAdded more narrative! Made this much easier to read if you’re not coming from this class\nFixed a bug caused by joining on identifier instead of SubjectNumber"
  },
  {
    "objectID": "presentation.html#tidy-tuesday",
    "href": "presentation.html#tidy-tuesday",
    "title": "Project 5 - Website Updates",
    "section": "Tidy Tuesday!",
    "text": "Tidy Tuesday!\n\nI’ve been to a few tidy tuesdays!\nThese were super easy to pop onto my website\nAdded this cool regex assignment to puff up the data science project"
  },
  {
    "objectID": "presentation.html#site-clean-up-and-tweaks",
    "href": "presentation.html#site-clean-up-and-tweaks",
    "title": "Project 5 - Website Updates",
    "section": "Site clean-up and tweaks",
    "text": "Site clean-up and tweaks\n\nAdded the correct links to my socials + headers\nRemoved error messages\nAdded images + Dark theme\nConsolidated all DS2R projects together"
  },
  {
    "objectID": "presentation.html#to-do",
    "href": "presentation.html#to-do",
    "title": "Project 5 - Website Updates",
    "section": "To-Do",
    "text": "To-Do\n\nGet that custom domain name!\nAdd my coding projects: I want this to be a portfolio/project website for recruiters\nAdd more flair + shiny stuff\nThank you!"
  },
  {
    "objectID": "project3.html",
    "href": "project3.html",
    "title": "Analyzing California School’s Tuition Costs",
    "section": "",
    "text": "Using the “College tuition, diversity, and pay” data set, I will be analyzing the differences in cost/tuition between public and private schools. I will filter out the data in order to make a fair comparison between the two categories (e.g. schools in the same region), then compare the difference between their costs. Here is a link to my data set: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-03-10/readme.md\nMy research questions - Tuition rates are higher for private universities than for public universities Null claim: Tuition rates do not differ between public and private universities.\nI am only interested in the total cost for students attending schools in-state, in California. This way, the cost-of-living is fairly looked at (since comparing Californiaa schools with Maine schools, for example, would not be fair).\n\nlibrary(dplyr)\nlibrary(dplyr)\n\n# Sorting my data:\nCA_schools &lt;- tuition_cost |&gt;\n  select(name, state_code, type, in_state_tuition) |&gt;\n  filter(state_code == \"CA\") |&gt;\n  filter(type %in% c(\"Public\", \"Private\"))\n\nCA_schools \n\n# A tibble: 239 × 4\n   name                                    state_code type    in_state_tuition\n   &lt;chr&gt;                                   &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt;\n 1 Allan Hancock College                   CA         Public              1418\n 2 Alliant International University        CA         Private            18000\n 3 American Academy of Dramatic Arts: West CA         Private            35160\n 4 American Jewish University              CA         Private            31826\n 5 American River College                  CA         Public              1416\n 6 Antelope Valley College                 CA         Public              1420\n 7 Antioch University Los Angeles          CA         Private            20670\n 8 Antioch University Santa Barbara        CA         Private            22575\n 9 Art Center College of Design            CA         Private            43416\n10 Azusa Pacific University                CA         Private            38880\n# ℹ 229 more rows\n\n\n\n# My function to simulate a random sampling of school's in-state tuition# My function to simulate a random sampling of school's in-state tuition\n\n# average\navg_cost &lt;- CA_schools |&gt;\n  group_by(type) |&gt;\n  summarize(avg_cost = mean(in_state_tuition))\n\navg_diff &lt;- CA_schools |&gt; \n  group_by(type) |&gt; \n  summarize(avg_cost = mean(in_state_tuition)) |&gt; \n  summarize(ave_diff = diff(avg_cost))\n\navg_diff_val &lt;- abs(avg_diff$ave_diff[1])\n\n# median\nmed_cost &lt;- CA_schools |&gt;\n  group_by(type) |&gt;\n  summarize(median_cost = median(in_state_tuition))\n\nmed_diff &lt;- CA_schools |&gt; \n  group_by(type) |&gt; \n  summarize(median_cost = median(in_state_tuition)) |&gt; \n  summarize(median_diff = diff(median_cost))\n\nmed_diff_val &lt;- abs(med_diff$median_diff[1])\n\n# average cost code\nperm_data &lt;- function(rep, data){\n  CA_schools |&gt;\n    select(type, in_state_tuition) |&gt; \n    mutate(perm_type = sample(type)) |&gt; \n    group_by(perm_type) |&gt; \n    dplyr::summarize(perm_cost = mean(in_state_tuition, na.rm = TRUE)) |&gt;\n    summarize(diff_perm = diff(perm_cost), rep = rep)\n}\n\n#map(1:10, perm_data, data = avg_diff) |&gt; \n#  list_rbind()\n\nset.seed(65)\n# 1000 iterations\nnum_exper &lt;- 5000\nsimulated_differences &lt;- map(1:num_exper, perm_data, data = avg_diff) |&gt; \n  list_rbind()\n\nsimulated_differences |&gt; \n  data.frame() |&gt; \n  ggplot(aes(x = diff_perm)) + \n  geom_histogram(binwidth = 1000, fill = \"black\", color = \"white\") + \n  geom_vline(xintercept = avg_diff_val, color = \"red\") + \n  labs(x = \"The difference of mean cost of attendance betwen Public and Private Universities\",\n       title = \"Sampling Distribution of Permuted Differences\") +\n  theme_dark()\n\n\n\n\n\n\n\np_val_avg &lt;- simulated_differences |&gt; \n  summarize(p_val_ave = mean(diff_perm &gt; avg_diff_val))\np_val_avg\n\n# A tibble: 1 × 1\n  p_val_ave\n      &lt;dbl&gt;\n1         0\n\n# median cost code\n\nperm_data_median &lt;- function(rep, data){\n  CA_schools |&gt;\n    select(type, in_state_tuition) |&gt; \n    mutate(perm_type = sample(type)) |&gt; \n    group_by(perm_type) |&gt; \n    dplyr::summarize(median_perm_cost = median(in_state_tuition, na.rm = TRUE)) |&gt;\n    summarize(median_diff_perm = diff(median_perm_cost), rep = rep)\n}\n\n#map(1:10, perm_data, data = avg_diff) |&gt; \n#  list_rbind()\n\nset.seed(47)\n# 1000 iterations\nnum_exper &lt;- 5000\nmedian_simulated_differences &lt;- map(1:num_exper, perm_data_median, data = med_diff_val) |&gt; \n  list_rbind()\n\nmedian_simulated_differences\n\n# A tibble: 5,000 × 2\n   median_diff_perm   rep\n              &lt;dbl&gt; &lt;int&gt;\n 1            -55.5     1\n 2           -548       2\n 3           -214.      3\n 4          -2763       4\n 5           5644.      5\n 6           6162.      6\n 7           5671       7\n 8            -20.5     8\n 9           -223       9\n10          -2543      10\n# ℹ 4,990 more rows\n\nmedian_simulated_differences |&gt; \n  data.frame() |&gt; \n  ggplot(aes(x = median_diff_perm)) + \n  geom_histogram(binwidth = 1000, fill = \"black\", color = \"white\") + \n  geom_vline(xintercept = med_diff_val, color = \"cyan\") + \n  labs(x = \"The difference of median cost of attendance betwen Public and Private Universities\",\n       title = \"Sampling Distribution of Permuted Differences\") +\n  theme_dark()\n\n\n\n\n\n\n\np_val_med &lt;- median_simulated_differences |&gt; \n  summarize(p_val_med = mean(median_diff_perm &gt; med_diff_val))\np_val_med\n\n# A tibble: 1 × 1\n  p_val_med\n      &lt;dbl&gt;\n1         0\n\n\nThis plot shows us the results from randomly shuffling the labels between public and private universities, and then measuring their mean difference.\nFrom these data, the observed differences seem to be consistent with the distribution of differences in the null sampling distribution. This holds true for the median cost of attendance as well.\nThere is very strong evidence to reject the null hypothesis - our p-value is zero!\nWe can claim that the tuition rates are higher for private universities than for public universities (p-value = 0).\nWe achieved this result by filtering for California schools, and then calculating the average mean between private and public schools in California. We then shuffled their labels, and ran this over 1000 iterations, and found that there is strong evidence for the null hypothesis in this case."
  }
]